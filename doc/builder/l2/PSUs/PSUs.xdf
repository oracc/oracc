<?xml version='1.0' encoding='utf-8'?>
<d:doc  xmlns="http://www.w3.org/1999/xhtml" 
	xmlns:d="http://oracc.org/ns/xdf/1.0"
	xmlns:dc="http://purl.org/dc/elements/1.1"
	xmlns:dcterms="http://purl.org/dc/terms/"
	xmlns:h="http://www.w3.org/1999/xhtml" 
   	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	>

<d:meta>
  <dc:title>PSUs: Phrasal Semantic Units</dc:title>
  <dcterms:alternative></dcterms:alternative>
  <dcterms:identifier 
      xsi:type="dcterms:URI"></dcterms:identifier>
  <dc:creator>Steve Tinney</dc:creator>
  <dc:date>2009-10-25</dc:date>
  <dc:publisher>Oracc</dc:publisher>
  <dc:description>This page describes how L2 handles Phrasal Semantic
  Units, or glossary entries which consist of more than one word.</dc:description>
</d:meta>

<h1>Introduction</h1>

<p>PSUs are phrases that warrant their own dictionary entry, or a
specific listing under one of the headwords.  Such phrases may have
their own meaning which is distinct from the sum of the parts, or they
may simply be idiomatic usages which it is interesting to include in
the glossary.</p>

<p>Although it is easy to be confused by the overlap caused by the
fact that many PSUs are written using COFs, the two are completely
separate.  As far as L2 is concerned, PSUs are simply sequences of
lemmata which are checked to ensure that the individual components
match known criteria.  COFs, on the other hand, are purely a feature
of the writing interface, and have nothing to do with the
interpretation of lemmata.</p>

<h2>Lemmatizing</h2>

<p>PSUs are lemmatized simply by lemmatizing the individual
components: a special layer of L2 is responsible for identifying the
phrases and linking the words together.  Note the following
considerations:</p>


<ul>
<li>
<p>When lemmatizing the words it is not generally necessary to give a
SENSE.  However, within the L2 system the constituent words of PSUs
are always associated with some SENSE of the word.  As a result, when
the GW of a word does not match a SENSE, it is better to give some
keywords of the SENSE when lemmatizing.  Also, some compounds and
idioms may use different SENSEs of a word; in this case, too, it is
necessary to give a SENSE when lemmatizing.</p>
</li>
<li>
<p>Sometimes a sequence of words should not be treated as a PSU even
though the sequence is listed in the glossary as such.  To prevent the
lemmatizer treating the sequence as a PSU, use <code>!</code> before
the first lemma of a PSU to show that it is NOT a PSU in this
instance. For instance, if <code>ana[to]PRP; ṭarsi[extent]N</code> is
in your glossary with the meaning "opposite", write <code>!ana[to]PRP;
ṭarsi[extent]N</code> when you want this phrase to keep its literal
meaning, "to an extent".  The mnemonic is that <code>!</code> is a
common boolean operator for <code>NOT</code>: the <code>!</code> tells
L2 *not* to process the word as part of a PSU.</p>
</li>
<li>
<p>You can use - before a lemma to omit a word (usually a MOD or AV)
from the middle of a PSU, e.g., <code>libbašu[interior]N; -ul[not]MOD;
iṭâb[be(come) good]V</code> for <code>libba ṭiābu [be(come) satisfied]
V</code>.</p>
</li>
<li>
<p>You can specify the sense of an idiom, in the GW of the first
Akkadian element, like this: <code>ŠA₃.HUL = +lumnu[evil+=eclipsed
state]N$lumun&amp;+libbu[interior]N$libbi,</code> where <i>lumun
libbi</i> has the GW “sorrow” but in some (mostly astronomical)
contexts means “eclipsed state”.</p>
</li>
</ul>

<h2>Glossarizing</h2>

<p>In the glossary, a PSU has its own <code>@entry</code>, and in
addition each of its constituents must have their own
<code>@entry</code>.  Each constituent must have all of the
information, including proper <code>@form</code> lines, as any other
word: the constituent entries are ignorant of the fact that they are
later gathered into PSUs.</p>

<p>A PSU <code>@entry</code> has one additional line relative to other
words: a <code>@parts</code> specification, which gives the sequence of
consituents which makes up the PSU:</p>

<pre class="cookbook">
@entry ēkal māšarti [review palace] N
@parts ēkallu[palace]N māšartu[inspection]N
...
@sense N review palace
@end entry
</pre>

<p>As with lemmatization, the constituents do not need an explicit
SENSE to be given unless there are multiple PSUs with the same
sequence of words but which differ in the SENSE of the one or more of
the constituents, or if the GW does not match any of the SENSEs of the
constituent.  See 'Diagnostics' below for examples.</p>

<p>Sometimes the constituents of a PSU may be written in more than one
order.  In such cases, the glossary simply needs multiple
<code>@part</code> lines:</p>

<pre class="cookbook">
@entry ina pān dagālu [wait for someone] V
@parts ina[in]PRP pānu[front]N dagālu[see]V
@parts dagālu[see]V ina[in]PRP pānu[front]N
</pre>

<p>The <code>@form</code> lines of PSUs also have some special
characteristics.  One is that the first element of a <code>@form</code>,
the written form, may contain multiple words: in this case they are
joined by underscores.  The other is that they may only contain NORM
entries in addition to the written form, and each of the NORMs is
prefixed by its own <code>$</code>-sign:</p>

<pre class="cookbook">
@form ina_pa-ni-šu₂-nu_a-da-gal $ina $pānišunu $adaggal
@form ina_pa-ni-šu₂-nu_i-da-gal $ina $pānišunu $idaggal
</pre>

<p>COFs in the written forms of PSUs are straightforward when the
entire PSU is written with a single COF:</p>

<pre class="cookbook">
@form im-muh-hi $ina $muhhi
</pre>

<p>When the writing mixes a COF with other constituents, however, it
is necessary to tell L2 how many of the NORMs of the
<code>@form</code> line are used up by the COF.  This is done by
adding the special sequence <code>_0</code> (underscore followed by
the digit zero) for each COF-constituent after the first:</p>

<pre class="cookbook">
@form {na₄}NIR₂.PA_0_iṣ-ṣu-ri $hulāl $kappi $iṣṣūri
</pre>

<h2>L2 Diagnostics</h2>

<h3>PSU component not found in glossary</h3>

<p>This diagnostic is generated when processing a <code>@form</code>
line which contains COF components indicated with parentheses.  The
diagnostic gives the line number of the COF <code>@form</code> which
is being processed, and indicates the spelling and an expected
normalization which has not been found.  Since the COF handling is not
tied to entries, but to spelling and normalization combinations, the
diagnostic cannot tell you which <code>@entry</code> it expected to
find the component in.</p>

<p>Here is an actual example:</p>

<pre class="example">
00lib/akk-x-neoass.glo:3167: (g2a) PSU component #2 
         i-da-a-ti=dāt[behind]PRP$dāti not found in glossary</pre>

<p>This tells you that at line 3167 in 00lib/akk-x-neoass.glo, a
defective <code>@form</code> line is being processed in a PSU
<code>@entry</code>.</p>

<p>The defect may be in any of several places.  When processing a
<code>@form</code> line, L2 takes each PSU component in turn, and
combines the written form and the normalization from the
<code>@form</code> line with the signature data from the relevant word
in the <code>@parts</code> line.  The number given in the error
message tells you the component of the form/parts lines it is currently
working on.</p>

<p>If more than one <code>@parts</code> line is given in the PSU
<code>@entry</code>, L2 tries all of the <code>@parts</code> lines to
find a complete set of matches before it reports errors.</p>

<p>To debug this error, visit the offending line in the glossary and
look at the contexts and the individual word entries.  Some common
causes of this error are:</p>

<ul>
<li><code>@form</code> line with its components out of order</li>
<li>the component word does not have a matching <code>@form</code>
line</li>
<li>the POS on the component in the <code>@part</code> line is
wrong</li>
<li>there is no matching SENSE for in the entry for the component</li>
</ul>

<p>In the example error, the current word is
<code>dāt[behind]PRP</code> Unless there is a bug in L2, you will find
that the expected form line is missing, in this case:</p>

<pre class="example">
@form i-da-ti $(ina) $dāti
</pre>

<p>Assuming that there is no typo and that the <code>@form</code>
entry really should be there, you can now fix it by simply editing the
glossary to add the <code>@form</code> line.</p>

</d:doc>
